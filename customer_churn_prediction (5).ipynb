{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/setigogoli/ML-project/blob/main/customer_churn_prediction%20(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stainless-prefix",
      "metadata": {
        "id": "stainless-prefix"
      },
      "source": [
        "**<center> <span style=\"color:#0F52BA;font-family:serif; font-size:34px;\">\n",
        "ML Project\\\n",
        "Setayesh Heydari 40104073\\\n",
        "Amir Hossein Shahrabi 401104208\\\n",
        "Amir Abbas Donyadideh 401104113\n",
        "</span> </center>**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "patient-statistics",
      "metadata": {
        "id": "patient-statistics"
      },
      "source": [
        "# Loading libraries and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spiritual-candy",
      "metadata": {
        "id": "spiritual-candy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "failing-consolidation",
      "metadata": {
        "id": "failing-consolidation"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"blastchar/telco-customer-churn\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "id": "QmD9OQl-DIBd"
      },
      "id": "QmD9OQl-DIBd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 1**"
      ],
      "metadata": {
        "id": "tfggWuSSIqSN"
      },
      "id": "tfggWuSSIqSN"
    },
    {
      "cell_type": "markdown",
      "id": "built-collins",
      "metadata": {
        "id": "built-collins"
      },
      "source": [
        "# Understanding the Data(Data Shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fleet-literacy",
      "metadata": {
        "id": "fleet-literacy"
      },
      "source": [
        "Each row represents a customer, each column contains customer’s attributes described on the column Metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "literary-proof",
      "metadata": {
        "id": "literary-proof"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "waiting-pharmaceutical",
      "metadata": {
        "id": "waiting-pharmaceutical"
      },
      "source": [
        "**The data set includes information about:**\n",
        "* **Customers who left within the last month** – the column is called Churn\n",
        "\n",
        "* **Services that each customer has signed up for** – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
        "\n",
        "* **Customer account information** - how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
        "\n",
        "* **Demographic info about customers** – gender, age range, and if they have partners and dependents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "macro-replication",
      "metadata": {
        "id": "macro-replication"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "complicated-norman",
      "metadata": {
        "id": "complicated-norman"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "delayed-sailing",
      "metadata": {
        "id": "delayed-sailing"
      },
      "outputs": [],
      "source": [
        "df.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coral-recommendation",
      "metadata": {
        "id": "coral-recommendation"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "developed-survivor",
      "metadata": {
        "id": "developed-survivor"
      },
      "source": [
        "\n",
        "* The target the we will use to guide the exploration is **Churn**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oQPiCrgTcHIH",
      "metadata": {
        "id": "oQPiCrgTcHIH"
      },
      "source": [
        "# Find duplicate rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LtUzYVgUcFrC",
      "metadata": {
        "id": "LtUzYVgUcFrC"
      },
      "outputs": [],
      "source": [
        "# ===== Find duplicate rows =====\n",
        "\n",
        "duplicate_rows = df.duplicated()\n",
        "\n",
        "print(\"Number of duplicate rows:\", duplicate_rows.sum())\n",
        "\n",
        "# See the duplicate rows (optional)\n",
        "df[duplicate_rows]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VmX5UgmdcVpN",
      "metadata": {
        "id": "VmX5UgmdcVpN"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates (keep first occurrence)\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Shape after removing duplicate rows:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "detailed-bradford",
      "metadata": {
        "id": "detailed-bradford"
      },
      "source": [
        "# Find & remove duplicate variables (columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yfc6OwYSc6x1",
      "metadata": {
        "id": "yfc6OwYSc6x1"
      },
      "outputs": [],
      "source": [
        "# ===== Find & remove duplicate variables (columns) =====\n",
        "\n",
        "# 1) Duplicate columns by *name* (exact same column label repeated)\n",
        "dup_name_mask = df.columns.duplicated()\n",
        "dup_name_cols = df.columns[dup_name_mask].tolist()\n",
        "\n",
        "if dup_name_cols:\n",
        "    print(\"Duplicate column names found:\", dup_name_cols)\n",
        "    # Keep first occurrence, drop the rest\n",
        "    df = df.loc[:, ~dup_name_mask]\n",
        "else:\n",
        "    print(\"No duplicate column names found.\")\n",
        "\n",
        "# 2) Duplicate columns by *content* (same values in every row)\n",
        "# Transpose to compare columns as rows, then find duplicates\n",
        "dup_content_mask = df.T.duplicated()\n",
        "dup_content_cols = df.columns[dup_content_mask].tolist()\n",
        "\n",
        "if dup_content_cols:\n",
        "    print(\"Duplicate columns by content found:\", dup_content_cols)\n",
        "    df = df.drop(columns=dup_content_cols)\n",
        "else:\n",
        "    print(\"No duplicate columns by content found.\")\n",
        "\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IF7sCq6xfF7-",
      "metadata": {
        "id": "IF7sCq6xfF7-"
      },
      "source": [
        "# Histogram using Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V_qQE-mZfUPP",
      "metadata": {
        "id": "V_qQE-mZfUPP"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.histplot(df[col], bins=30, kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67HpJNi5guTw",
      "metadata": {
        "id": "67HpJNi5guTw"
      },
      "source": [
        "#Histogram using seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hy9eCDPVfZcP",
      "metadata": {
        "id": "Hy9eCDPVfZcP"
      },
      "outputs": [],
      "source": [
        "# Select numeric columns automatically\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Plot histograms\n",
        "df[numeric_cols].hist(figsize=(12, 8), bins=30)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "re7Kk61ag1Ju",
      "metadata": {
        "id": "re7Kk61ag1Ju"
      },
      "source": [
        "# histogeram other way\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cwwXk6DVfdRB",
      "metadata": {
        "id": "cwwXk6DVfdRB"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "for col in numeric_cols:\n",
        "    fig = px.histogram(df, x=col, nbins=30, title=f'Distribution of {col}')\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ULKTrASnf43k",
      "metadata": {
        "id": "ULKTrASnf43k"
      },
      "source": [
        "# bar plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDLZ6HXKf2-P",
      "metadata": {
        "id": "hDLZ6HXKf2-P"
      },
      "outputs": [],
      "source": [
        "# Select categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Remove customerID (not useful for plotting)\n",
        "categorical_cols = categorical_cols.drop('customerID')\n",
        "\n",
        "categorical_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "guw_BHGJg907",
      "metadata": {
        "id": "guw_BHGJg907"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 25))\n",
        "\n",
        "for i, col in enumerate(categorical_cols, 1):\n",
        "    plt.subplot(len(categorical_cols)//2 + 1, 2, i)\n",
        "    sns.countplot(x=col, data=df)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar plot other way"
      ],
      "metadata": {
        "id": "IdSNzircgR8a"
      },
      "id": "IdSNzircgR8a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m3RfZ9xFhIRE",
      "metadata": {
        "id": "m3RfZ9xFhIRE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 25))\n",
        "\n",
        "for i, col in enumerate(categorical_cols, 1):\n",
        "    plt.subplot(len(categorical_cols)//2 + 1, 2, i)\n",
        "\n",
        "    df[col].value_counts().plot(kind='bar')\n",
        "\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qypm5AVeheF0",
      "metadata": {
        "id": "Qypm5AVeheF0"
      },
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "    fig = px.histogram(df, x=col, title=f'Distribution of {col}')\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "maritime-episode",
      "metadata": {
        "id": "maritime-episode"
      },
      "source": [
        "<a id = \"7\" ></a>\n",
        "# <span style=\"font-family:serif; font-size:28px;\"> 4. Visualize missing values </span>\n",
        "<a id = \"missingvalue\" ></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "insured-israeli",
      "metadata": {
        "id": "insured-israeli"
      },
      "outputs": [],
      "source": [
        "# Visualize missing values as a matrix\n",
        "msno.matrix(df);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tropical-humanity",
      "metadata": {
        "id": "tropical-humanity"
      },
      "source": [
        "> Using this matrix we can very quickly find the pattern of missingness in the dataset.\n",
        "* From the above visualisation we can observe that it has no peculiar pattern that stands out. In fact there is no missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "enormous-reflection",
      "metadata": {
        "id": "enormous-reflection"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shared-overview",
      "metadata": {
        "id": "shared-overview"
      },
      "source": [
        "# Data Manipulation(finding missing values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-prisoner",
      "metadata": {
        "id": "transsexual-prisoner"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['customerID'], axis = 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leading-mississippi",
      "metadata": {
        "id": "leading-mississippi"
      },
      "source": [
        "* On deep analysis, we can find some indirect missingness in our data (which can be in form of blankspaces). Let's see that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "asian-consideration",
      "metadata": {
        "id": "asian-consideration"
      },
      "outputs": [],
      "source": [
        "df['TotalCharges'] = pd.to_numeric(df.TotalCharges, errors='coerce')\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "secure-concert",
      "metadata": {
        "id": "secure-concert"
      },
      "source": [
        "* Here we see that the TotalCharges has 11 missing values. Let's check this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compressed-diving",
      "metadata": {
        "id": "compressed-diving"
      },
      "outputs": [],
      "source": [
        "df[np.isnan(df['TotalCharges'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "advanced-ability",
      "metadata": {
        "id": "advanced-ability"
      },
      "source": [
        "* It can also be noted that the Tenure column is 0 for these entries even though the MonthlyCharges column is not empty.\n",
        "\n",
        "Let's see if there are any other 0 values in the tenure column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shaped-maximum",
      "metadata": {
        "id": "shaped-maximum"
      },
      "outputs": [],
      "source": [
        "df[df['tenure'] == 0].index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "young-shade",
      "metadata": {
        "id": "young-shade"
      },
      "source": [
        "* There are no additional missing values in the Tenure column.\n",
        "\n",
        "Let's delete the rows with missing values in Tenure columns since there are only 11 rows and deleting them will not affect the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprised-powder",
      "metadata": {
        "id": "surprised-powder"
      },
      "outputs": [],
      "source": [
        "df.drop(labels=df[df['tenure'] == 0].index, axis=0, inplace=True)\n",
        "df[df['tenure'] == 0].index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outer-works",
      "metadata": {
        "id": "outer-works"
      },
      "source": [
        "> To solve the problem of missing values in TotalCharges column, I decided to fill it with the mean of TotalCharges values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0PDgmJXpO05",
      "metadata": {
        "id": "d0PDgmJXpO05"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boolean-budapest",
      "metadata": {
        "id": "boolean-budapest"
      },
      "outputs": [],
      "source": [
        "df.fillna(df[\"TotalCharges\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "solved-shipping",
      "metadata": {
        "id": "solved-shipping"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legal-vatican",
      "metadata": {
        "id": "legal-vatican"
      },
      "outputs": [],
      "source": [
        "df[\"SeniorCitizen\"]= df[\"SeniorCitizen\"].map({0: \"No\", 1: \"Yes\"})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pointed-maintenance",
      "metadata": {
        "id": "pointed-maintenance"
      },
      "outputs": [],
      "source": [
        "df[\"InternetService\"].describe(include=['object', 'bool'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wooden-sodium",
      "metadata": {
        "id": "wooden-sodium"
      },
      "outputs": [],
      "source": [
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "df[numerical_cols].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bc3-3pCDppY7",
      "metadata": {
        "id": "Bc3-3pCDppY7"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "orange-juvenile",
      "metadata": {
        "id": "orange-juvenile"
      },
      "source": [
        "#distribution analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "returning-assistant",
      "metadata": {
        "id": "returning-assistant"
      },
      "outputs": [],
      "source": [
        "g_labels = ['Male', 'Female']\n",
        "c_labels = ['No', 'Yes']\n",
        "# Create subplots: use 'domain' type for Pie subplot\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
        "fig.add_trace(go.Pie(labels=g_labels, values=df['gender'].value_counts(), name=\"Gender\"),\n",
        "              1, 1)\n",
        "fig.add_trace(go.Pie(labels=c_labels, values=df['Churn'].value_counts(), name=\"Churn\"),\n",
        "              1, 2)\n",
        "\n",
        "# Use `hole` to create a donut-like pie chart\n",
        "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\", textfont_size=16)\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=\"Gender and Churn Distributions\",\n",
        "    # Add annotations in the center of the donut pies.\n",
        "    annotations=[dict(text='Gender', x=0.16, y=0.5, font_size=20, showarrow=False),\n",
        "                 dict(text='Churn', x=0.84, y=0.5, font_size=20, showarrow=False)])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "commercial-murray",
      "metadata": {
        "id": "commercial-murray"
      },
      "source": [
        "* 26.6 % of customers switched to another firm.\n",
        "* Customers are 49.5 % female and 50.5 % male."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "senior-mistress",
      "metadata": {
        "id": "senior-mistress"
      },
      "outputs": [],
      "source": [
        "df[\"Churn\"][df[\"Churn\"]==\"No\"].groupby(by=df[\"gender\"]).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "residential-rider",
      "metadata": {
        "id": "residential-rider"
      },
      "outputs": [],
      "source": [
        "df[\"Churn\"][df[\"Churn\"]==\"Yes\"].groupby(by=df[\"gender\"]).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "final-embassy",
      "metadata": {
        "id": "final-embassy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "labels =[\"Churn: Yes\",\"Churn:No\"]\n",
        "values = [1869,5163]\n",
        "labels_gender = [\"F\",\"M\",\"F\",\"M\"]\n",
        "sizes_gender = [939,930 , 2544,2619]\n",
        "colors = ['#ff6666', '#66b3ff']\n",
        "colors_gender = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\n",
        "explode = (0.3,0.3)\n",
        "explode_gender = (0.1,0.1,0.1,0.1)\n",
        "textprops = {\"fontsize\":15}\n",
        "#Plot\n",
        "plt.pie(values, labels=labels,autopct='%1.1f%%',pctdistance=1.08, labeldistance=0.8,colors=colors, startangle=90,frame=True, explode=explode,radius=10, textprops =textprops, counterclock = True, )\n",
        "plt.pie(sizes_gender,labels=labels_gender,colors=colors_gender,startangle=90, explode=explode_gender,radius=7, textprops =textprops, counterclock = True, )\n",
        "#Draw circle\n",
        "centre_circle = plt.Circle((0,0),5,color='black', fc='white',linewidth=0)\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "\n",
        "plt.title('Churn Distribution w.r.t Gender: Male(M), Female(F)', fontsize=15, y=1.1)\n",
        "\n",
        "# show plot\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interracial-chosen",
      "metadata": {
        "id": "interracial-chosen"
      },
      "source": [
        "* There is negligible difference in customer percentage/ count who chnaged the service provider. Both genders behaved in similar fashion when it comes to migrating to another service provider/firm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "passive-copper",
      "metadata": {
        "id": "passive-copper"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df, x=\"Churn\", color=\"Contract\", barmode=\"group\", title=\"<b>Customer contract distribution<b>\")\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "seeing-timber",
      "metadata": {
        "id": "seeing-timber"
      },
      "source": [
        "* About 75% of customer with Month-to-Month Contract opted to move out as compared to 13% of customrs with One Year Contract and 3% with Two Year Contract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "governing-makeup",
      "metadata": {
        "id": "governing-makeup"
      },
      "outputs": [],
      "source": [
        "labels = df['PaymentMethod'].unique()\n",
        "values = df['PaymentMethod'].value_counts()\n",
        "\n",
        "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
        "fig.update_layout(title_text=\"<b>Payment Method Distribution</b>\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enormous-silly",
      "metadata": {
        "id": "enormous-silly"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df, x=\"Churn\", color=\"PaymentMethod\", title=\"<b>Customer Payment Method distribution w.r.t. Churn</b>\")\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prospective-trainer",
      "metadata": {
        "id": "prospective-trainer"
      },
      "source": [
        "* Major customers who moved out were having Electronic Check as Payment Method.\n",
        "* Customers who opted for Credit-Card automatic transfer or Bank Automatic Transfer and Mailed Check as Payment Method were less likely to move out.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "charming-hollywood",
      "metadata": {
        "id": "charming-hollywood"
      },
      "outputs": [],
      "source": [
        "df[\"InternetService\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advanced-destination",
      "metadata": {
        "id": "advanced-destination"
      },
      "outputs": [],
      "source": [
        "df[df[\"gender\"]==\"Male\"][[\"InternetService\", \"Churn\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "useful-plane",
      "metadata": {
        "id": "useful-plane"
      },
      "outputs": [],
      "source": [
        "df[df[\"gender\"]==\"Female\"][[\"InternetService\", \"Churn\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dutch-confusion",
      "metadata": {
        "id": "dutch-confusion"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
        "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
        "  y = [965, 992, 219, 240],\n",
        "  name = 'DSL',\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
        "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
        "  y = [889, 910, 664, 633],\n",
        "  name = 'Fiber optic',\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
        "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
        "  y = [690, 717, 56, 57],\n",
        "  name = 'No Internet',\n",
        "))\n",
        "\n",
        "fig.update_layout(title_text=\"<b>Churn Distribution w.r.t. Internet Service and Gender</b>\")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "according-phone",
      "metadata": {
        "id": "according-phone"
      },
      "source": [
        "* A lot of customers choose the Fiber optic service and it's also evident that the customers who use Fiber optic have high churn rate, this might suggest a dissatisfaction with this type of internet service.\n",
        "* Customers having DSL service are majority in number and have less churn rate compared to Fibre optic service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "descending-hours",
      "metadata": {
        "id": "descending-hours"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": \"#FF97FF\", \"No\": \"#AB63FA\"}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"Dependents\", barmode=\"group\", title=\"<b>Dependents distribution</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "protective-president",
      "metadata": {
        "id": "protective-president"
      },
      "source": [
        "* Customers without dependents are more likely to churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metropolitan-carpet",
      "metadata": {
        "id": "metropolitan-carpet"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"Partner\", barmode=\"group\", title=\"<b>Chrun distribution w.r.t. Partners</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fleet-perry",
      "metadata": {
        "id": "fleet-perry"
      },
      "source": [
        "* Customers that doesn't have partners are more likely to churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silent-institution",
      "metadata": {
        "id": "silent-institution"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": '#00CC96', \"No\": '#B6E880'}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"SeniorCitizen\", title=\"<b>Chrun distribution w.r.t. Senior Citizen</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tamil-pathology",
      "metadata": {
        "id": "tamil-pathology"
      },
      "source": [
        "* It can be observed that the fraction of senior citizen is very less.\n",
        "* Most of the senior citizens churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "assisted-capability",
      "metadata": {
        "id": "assisted-capability"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": \"#FF97FF\", \"No\": \"#AB63FA\"}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"OnlineSecurity\", barmode=\"group\", title=\"<b>Churn w.r.t Online Security</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quick-blank",
      "metadata": {
        "id": "quick-blank"
      },
      "source": [
        "* Most customers churn in the absence of online security,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adverse-ultimate",
      "metadata": {
        "id": "adverse-ultimate"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"PaperlessBilling\",  title=\"<b>Chrun distribution w.r.t. Paperless Billing</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "social-accordance",
      "metadata": {
        "id": "social-accordance"
      },
      "source": [
        "* Customers with Paperless Billing are most likely to churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "medieval-exclusion",
      "metadata": {
        "id": "medieval-exclusion"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df, x=\"Churn\", color=\"TechSupport\",barmode=\"group\",  title=\"<b>Chrun distribution w.r.t. TechSupport</b>\")\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "injured-weekend",
      "metadata": {
        "id": "injured-weekend"
      },
      "source": [
        "* Customers with no TechSupport are most likely to migrate to another service provider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ordinary-token",
      "metadata": {
        "id": "ordinary-token"
      },
      "outputs": [],
      "source": [
        "color_map = {\"Yes\": '#00CC96', \"No\": '#B6E880'}\n",
        "fig = px.histogram(df, x=\"Churn\", color=\"PhoneService\", title=\"<b>Chrun distribution w.r.t. Phone Service</b>\", color_discrete_map=color_map)\n",
        "fig.update_layout(width=700, height=500, bargap=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fleet-reasoning",
      "metadata": {
        "id": "fleet-reasoning"
      },
      "source": [
        "* Very small fraction of customers don't have a phone service and out of that, 1/3rd Customers are more likely to churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "relevant-henry",
      "metadata": {
        "id": "relevant-henry"
      },
      "outputs": [],
      "source": [
        "sns.set_context(\"paper\",font_scale=1.1)\n",
        "ax = sns.kdeplot(df.MonthlyCharges[(df[\"Churn\"] == 'No') ],\n",
        "                color=\"Red\", shade = True);\n",
        "ax = sns.kdeplot(df.MonthlyCharges[(df[\"Churn\"] == 'Yes') ],\n",
        "                ax =ax, color=\"Blue\", shade= True);\n",
        "ax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\n",
        "ax.set_ylabel('Density');\n",
        "ax.set_xlabel('Monthly Charges');\n",
        "ax.set_title('Distribution of monthly charges by churn');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaging-spice",
      "metadata": {
        "id": "engaging-spice"
      },
      "source": [
        "* Customers with higher Monthly Charges are also more likely to churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deluxe-basics",
      "metadata": {
        "id": "deluxe-basics"
      },
      "outputs": [],
      "source": [
        "ax = sns.kdeplot(df.TotalCharges[(df[\"Churn\"] == 'No') ],\n",
        "                color=\"Gold\", shade = True);\n",
        "ax = sns.kdeplot(df.TotalCharges[(df[\"Churn\"] == 'Yes') ],\n",
        "                ax =ax, color=\"Green\", shade= True);\n",
        "ax.legend([\"Not Chu0rn\",\"Churn\"],loc='upper right');\n",
        "ax.set_ylabel('Density');\n",
        "ax.set_xlabel('Total Charges');\n",
        "ax.set_title('Distribution of total charges by churn');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Heat Map"
      ],
      "metadata": {
        "id": "CUYpp1CdkUXC"
      },
      "id": "CUYpp1CdkUXC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intermediate-olive",
      "metadata": {
        "id": "intermediate-olive"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 10))\n",
        "\n",
        "corr = df.apply(lambda x: pd.factorize(x)[0]).corr()\n",
        "\n",
        "# Create a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "ax = sns.heatmap(corr, mask=mask, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, linewidths=.2, cmap='coolwarm', vmin=-1, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "social-freight",
      "metadata": {
        "id": "social-freight"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KhpTpmR3mtT2",
      "metadata": {
        "id": "KhpTpmR3mtT2"
      },
      "source": [
        "# Box Plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bOg9MvVmjBa",
      "metadata": {
        "id": "5bOg9MvVmjBa"
      },
      "source": [
        "Tenure vs Churn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8xDqY1A9mZMA",
      "metadata": {
        "id": "8xDqY1A9mZMA"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df, x='Churn', y='tenure', color='Churn')\n",
        "\n",
        "fig.update_yaxes(title_text='Tenure (Months)')\n",
        "fig.update_xaxes(title_text='Churn')\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=True,\n",
        "    width=750,\n",
        "    height=600,\n",
        "    title_font=dict(size=25, family='Courier'),\n",
        "    title='<b>Tenure vs Churn</b>'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mFcNVPn8mQiu",
      "metadata": {
        "id": "mFcNVPn8mQiu"
      },
      "source": [
        "MonthlyCharges vs Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZlFmGBKomQPI",
      "metadata": {
        "id": "ZlFmGBKomQPI"
      },
      "outputs": [],
      "source": [
        "fig = px.box(df, x='Churn', y='MonthlyCharges', color='Churn')\n",
        "\n",
        "fig.update_yaxes(title_text='Monthly Charges')\n",
        "fig.update_xaxes(title_text='Churn')\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=True,\n",
        "    width=750,\n",
        "    height=600,\n",
        "    title_font=dict(size=25, family='Courier'),\n",
        "    title='<b>Monthly Charges vs Churn</b>'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QfPD28cnm1vc",
      "metadata": {
        "id": "QfPD28cnm1vc"
      },
      "source": [
        "TotalCharges vs Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vG7YuExOm4o9",
      "metadata": {
        "id": "vG7YuExOm4o9"
      },
      "outputs": [],
      "source": [
        "#Make sure it's numeric first\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"TotalCharges\"])\n",
        "\n",
        "fig = px.box(df, x='Churn', y='TotalCharges', color='Churn')\n",
        "\n",
        "fig.update_yaxes(title_text='Total Charges')\n",
        "fig.update_xaxes(title_text='Churn')\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=True,\n",
        "    width=750,\n",
        "    height=600,\n",
        "    title_font=dict(size=25, family='Courier'),\n",
        "    title='<b>Total Charges vs Churn</b>'\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LEF-bI5NnKAA",
      "metadata": {
        "id": "LEF-bI5NnKAA"
      },
      "source": [
        "all in one code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3yfoiKm4nEbU",
      "metadata": {
        "id": "3yfoiKm4nEbU"
      },
      "outputs": [],
      "source": [
        "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "for col in numeric_cols:\n",
        "    fig = px.box(df, x='Churn', y=col, color='Churn',\n",
        "                 title=f'<b>{col} vs Churn</b>')\n",
        "\n",
        "    fig.update_layout(width=750, height=600)\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "premium-prisoner",
      "metadata": {
        "id": "premium-prisoner"
      },
      "source": [
        "* New customers are more likely to churn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 2**"
      ],
      "metadata": {
        "id": "AThSlamuH3P0"
      },
      "id": "AThSlamuH3P0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Imputation\n"
      ],
      "metadata": {
        "id": "43zJNrQ7i-iu"
      },
      "id": "43zJNrQ7i-iu"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert TotalCharges to numeric (blank strings -> NaN)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Separate numeric and categorical columns\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n"
      ],
      "metadata": {
        "id": "AOyy_oiwjGvB"
      },
      "id": "AOyy_oiwjGvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric: fill NaN with median (robust)\n",
        "for col in num_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Categorical: fill NaN with most frequent value (mode)\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Check\n",
        "print(\"Missing values after imputation:\\n\", df.isnull().sum()[df.isnull().sum() > 0])\n"
      ],
      "metadata": {
        "id": "p6d9m8LCjHh7"
      },
      "id": "p6d9m8LCjHh7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "another way"
      ],
      "metadata": {
        "id": "suhxhBeUjOB9"
      },
      "id": "suhxhBeUjOB9"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Convert TotalCharges to numeric\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Split X/y\n",
        "X = df.drop(columns=[\"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# Identify columns\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
        "\n",
        "# Preprocessors\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Example split (optional)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Fit/transform\n",
        "X_train_prepared = preprocessor.fit_transform(X_train)\n",
        "X_test_prepared  = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"Done. Shapes:\", X_train_prepared.shape, X_test_prepared.shape)\n"
      ],
      "metadata": {
        "id": "3Kn9CJ7cjPk9"
      },
      "id": "3Kn9CJ7cjPk9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lable Encoding"
      ],
      "metadata": {
        "id": "5q0VFGKujUSQ"
      },
      "id": "5q0VFGKujUSQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Find binary columns (exactly 2 unique values)\n",
        "binary_cols = [col for col in cat_cols if df[col].nunique() == 2]\n",
        "\n",
        "print(\"Binary columns:\")\n",
        "print(binary_cols)\n"
      ],
      "metadata": {
        "id": "wWRjLXHsjZaU"
      },
      "id": "wWRjLXHsjZaU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in binary_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "IjCqTZccjb6R"
      },
      "id": "IjCqTZccjb6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[binary_cols].head()"
      ],
      "metadata": {
        "id": "hJ7EHB8yja1B"
      },
      "id": "hJ7EHB8yja1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One Hot Encoding"
      ],
      "metadata": {
        "id": "u7aAzHRejjhf"
      },
      "id": "u7aAzHRejjhf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Select columns with more than 2 unique values\n",
        "multi_cols = [col for col in cat_cols if df[col].nunique() > 2]\n",
        "\n",
        "print(\"Multi-category columns:\")\n",
        "print(multi_cols)\n"
      ],
      "metadata": {
        "id": "3YX-iSzDjowc"
      },
      "id": "3YX-iSzDjowc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=multi_cols, drop_first=True)\n",
        "\n",
        "df.head()\n",
        "print(\"New shape after One-Hot Encoding:\", df.shape)\n"
      ],
      "metadata": {
        "id": "DFoWnvxnjrVH"
      },
      "id": "DFoWnvxnjrVH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "another way"
      ],
      "metadata": {
        "id": "pE-LW053j0Hw"
      },
      "id": "pE-LW053j0Hw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 1) Recompute multi-category columns from CURRENT df (only object columns with >2 unique values)\n",
        "multi_cols = [c for c in df.columns if df[c].dtype == \"object\" and df[c].nunique() > 2]\n",
        "\n",
        "print(\"Multi-category columns to one-hot encode:\", multi_cols)\n",
        "\n",
        "# If nothing left to encode, stop safely\n",
        "if len(multi_cols) == 0:\n",
        "    print(\"No multi-category object columns left to encode.\")\n",
        "else:\n",
        "    # 2) One-hot encode\n",
        "    ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
        "    encoded = ohe.fit_transform(df[multi_cols])\n",
        "\n",
        "    encoded_df = pd.DataFrame(\n",
        "        encoded,\n",
        "        columns=ohe.get_feature_names_out(multi_cols),\n",
        "        index=df.index\n",
        "    )\n",
        "\n",
        "    # 3) Replace original columns with encoded columns\n",
        "    df = df.drop(columns=multi_cols)\n",
        "    df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "    print(\"Done. New shape:\", df.shape)\n"
      ],
      "metadata": {
        "id": "9sUXz6Hhj4Ux"
      },
      "id": "9sUXz6Hhj4Ux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_cols = [c for c in df.columns if df[c].dtype == \"object\" and df[c].nunique() >= 2]\n"
      ],
      "metadata": {
        "id": "ULKGpHm-kCxq"
      },
      "id": "ULKGpHm-kCxq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "basic-dependence",
      "metadata": {
        "id": "basic-dependence"
      },
      "source": [
        "## train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wicked-directive",
      "metadata": {
        "id": "wicked-directive"
      },
      "outputs": [],
      "source": [
        "def object_to_int(dataframe_series):\n",
        "    if dataframe_series.dtype=='object':\n",
        "        dataframe_series = LabelEncoder().fit_transform(dataframe_series)\n",
        "    return dataframe_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verbal-culture",
      "metadata": {
        "id": "verbal-culture"
      },
      "outputs": [],
      "source": [
        "df = df.apply(lambda x: object_to_int(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cheap-writing",
      "metadata": {
        "id": "cheap-writing"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "df.corr()['Churn'].sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "confirmed-daisy",
      "metadata": {
        "id": "confirmed-daisy"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = ['Churn'])\n",
        "y = df['Churn'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "medium-architecture",
      "metadata": {
        "id": "medium-architecture"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 40, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moderate-civilian",
      "metadata": {
        "id": "moderate-civilian"
      },
      "outputs": [],
      "source": [
        "def distplot(feature, frame, color='r'):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.title(\"Distribution for {}\".format(feature))\n",
        "    ax = sns.distplot(frame[feature], color= color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "understanding-suite",
      "metadata": {
        "id": "understanding-suite"
      },
      "outputs": [],
      "source": [
        "num_cols = [\"tenure\", 'MonthlyCharges', 'TotalCharges']\n",
        "for feat in num_cols: distplot(feat, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sealed-representation",
      "metadata": {
        "id": "sealed-representation"
      },
      "source": [
        "Since the numerical features are distributed over different value ranges, I will use standard scalar to scale them down to the same range."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "still-gabriel",
      "metadata": {
        "id": "still-gabriel"
      },
      "source": [
        "#Standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-massachusetts",
      "metadata": {
        "id": "rational-massachusetts"
      },
      "outputs": [],
      "source": [
        "df_std = pd.DataFrame(StandardScaler().fit_transform(df[num_cols].astype('float64')),\n",
        "                       columns=num_cols)\n",
        "for feat in numerical_cols: distplot(feat, df_std, color='c')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mysterious-pasta",
      "metadata": {
        "id": "mysterious-pasta"
      },
      "outputs": [],
      "source": [
        "# Divide the columns into 3 categories, one ofor standardisation, one for label encoding and one for one hot encoding\n",
        "\n",
        "cat_cols_ohe =['PaymentMethod', 'Contract', 'InternetService'] # those that need one-hot encoding\n",
        "cat_cols_le = list(set(X_train.columns)- set(num_cols) - set(cat_cols_ohe)) #those that need label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "medium-balloon",
      "metadata": {
        "id": "medium-balloon"
      },
      "outputs": [],
      "source": [
        "scaler= StandardScaler()\n",
        "\n",
        "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "X_test[num_cols] = scaler.transform(X_test[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 3**"
      ],
      "metadata": {
        "id": "GCfPOgoeIvTI"
      },
      "id": "GCfPOgoeIvTI"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ── make sure boolean columns are int (required for chi2) ──\n",
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "df[bool_cols] = df[bool_cols].astype(int)"
      ],
      "metadata": {
        "id": "52kKQNEuT4s7"
      },
      "id": "52kKQNEuT4s7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering — Creating 2 new meaningful features\n"
      ],
      "metadata": {
        "id": "tRSAdBAEVKza"
      },
      "id": "tRSAdBAEVKza"
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Feature 1: Tenure Group (بازه‌بندی tenure) ──────────────\n",
        "# Binning tenure into meaningful loyalty segments\n",
        "def tenure_group(tenure):\n",
        "    if tenure <= 12:\n",
        "        return 0   # New Customer (0–1 year)\n",
        "    elif tenure <= 24:\n",
        "        return 1   # Developing (1–2 years)\n",
        "    elif tenure <= 48:\n",
        "        return 2   # Established (2–4 years)\n",
        "    else:\n",
        "        return 3   # Loyal (4+ years)\n",
        "\n",
        "df['Tenure_Group'] = df['tenure'].apply(tenure_group)\n",
        "\n",
        "print(\"Tenure Group distribution:\")\n",
        "print(df['Tenure_Group'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# ── Feature 2: Charges per Month Ratio ──────────────────────\n",
        "# TotalCharges / tenure gives average spend per month\n",
        "# This reveals if a customer's spending is consistent or changed\n",
        "df['Avg_Monthly_Spend'] = df['TotalCharges'] / (df['tenure'] + 1)\n",
        "# (+1 to avoid division by zero for tenure=0)\n",
        "\n",
        "# ── Feature 3: Service Count ────────────────────────────────\n",
        "# How many add-on services does each customer subscribe to?\n",
        "# More services → higher switching cost → lower churn probability\n",
        "service_cols = [\n",
        "    'MultipleLines_Yes',\n",
        "    'OnlineSecurity_Yes',\n",
        "    'OnlineBackup_Yes',\n",
        "    'DeviceProtection_Yes',\n",
        "    'TechSupport_Yes',\n",
        "    'StreamingTV_Yes',\n",
        "    'StreamingMovies_Yes'\n",
        "]\n",
        "df['Service_Count'] = df[service_cols].sum(axis=1)\n",
        "\n",
        "print(\"New features added:\")\n",
        "print(df[['tenure', 'Tenure_Group', 'TotalCharges',\n",
        "          'Avg_Monthly_Spend', 'Service_Count']].head(10))\n",
        "print()\n",
        "print(\"Correlation of new features with Churn:\")\n",
        "print(df[['Tenure_Group', 'Avg_Monthly_Spend',\n",
        "          'Service_Count', 'Churn']].corr()['Churn'])\n"
      ],
      "metadata": {
        "id": "WQhv1mcbVL7u"
      },
      "id": "WQhv1mcbVL7u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter-Based Selection (Chi-Squared + ANOVA)"
      ],
      "metadata": {
        "id": "Yd60mF_EVS_j"
      },
      "id": "Yd60mF_EVS_j"
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "# ── Scale numerical features to [0,1] for Chi2 ──────────────\n",
        "# Chi2 requires non-negative values\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(X),\n",
        "    columns=X.columns\n",
        ")\n"
      ],
      "metadata": {
        "id": "WujdFkDgVTtL"
      },
      "id": "WujdFkDgVTtL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Squared Test (for categorical/binary features)"
      ],
      "metadata": {
        "id": "FiI4QMS-VYxo"
      },
      "id": "FiI4QMS-VYxo"
    },
    {
      "cell_type": "code",
      "source": [
        "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
        "chi2_selector.fit(X_scaled, y)\n",
        "\n",
        "chi2_scores = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Chi2_Score': chi2_selector.scores_,\n",
        "    'P_Value': chi2_selector.pvalues_\n",
        "}).sort_values('Chi2_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"Chi-Squared Scores (Top 15):\")\n",
        "print(\"=\" * 55)\n",
        "print(chi2_scores.head(15).to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Plot Chi2\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(\n",
        "    data=chi2_scores.head(15),\n",
        "    x='Chi2_Score',\n",
        "    y='Feature',\n",
        "    palette='Blues_r'\n",
        ")\n",
        "plt.title('Top 15 Features — Chi-Squared Test', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Chi² Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qj6qv3gvVZdX"
      },
      "id": "Qj6qv3gvVZdX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANOVA F-Test (better for continuous numerical features)"
      ],
      "metadata": {
        "id": "Y4ko-DfSVd3n"
      },
      "id": "Y4ko-DfSVd3n"
    },
    {
      "cell_type": "code",
      "source": [
        "anova_selector = SelectKBest(score_func=f_classif, k='all')\n",
        "anova_selector.fit(X_scaled, y)\n",
        "\n",
        "anova_scores = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'ANOVA_F_Score': anova_selector.scores_,\n",
        "    'P_Value': anova_selector.pvalues_\n",
        "}).sort_values('ANOVA_F_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"ANOVA F-Scores (Top 15):\")\n",
        "print(\"=\" * 55)\n",
        "print(anova_scores.head(15).to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Plot ANOVA\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(\n",
        "    data=anova_scores.head(15),\n",
        "    x='ANOVA_F_Score',\n",
        "    y='Feature',\n",
        "    palette='Greens_r'\n",
        ")\n",
        "plt.title('Top 15 Features — ANOVA F-Test', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('ANOVA F-Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GFJz5mEwVen_"
      },
      "id": "GFJz5mEwVen_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Filter Score"
      ],
      "metadata": {
        "id": "XC3fGnWhVlMP"
      },
      "id": "XC3fGnWhVlMP"
    },
    {
      "cell_type": "code",
      "source": [
        "filter_combined = chi2_scores[['Feature', 'Chi2_Score']].merge(\n",
        "    anova_scores[['Feature', 'ANOVA_F_Score']], on='Feature'\n",
        ")\n",
        "# Normalize both scores to [0,1] and average them\n",
        "filter_combined['Chi2_norm']  = (filter_combined['Chi2_Score'] /\n",
        "                                  filter_combined['Chi2_Score'].max())\n",
        "filter_combined['ANOVA_norm'] = (filter_combined['ANOVA_F_Score'] /\n",
        "                                  filter_combined['ANOVA_F_Score'].max())\n",
        "filter_combined['Combined_Score'] = (filter_combined['Chi2_norm'] +\n",
        "                                      filter_combined['ANOVA_norm']) / 2\n",
        "filter_combined = filter_combined.sort_values(\n",
        "    'Combined_Score', ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "top15_filter = filter_combined.head(15)['Feature'].tolist()\n",
        "print(\"Top 15 Features by Combined Filter Score:\")\n",
        "print(top15_filter)"
      ],
      "metadata": {
        "id": "mf0A3D9OVkGY"
      },
      "id": "mf0A3D9OVkGY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso Regression (L1 — drives irrelevant features to 0)"
      ],
      "metadata": {
        "id": "zu1nqXGRVopP"
      },
      "id": "zu1nqXGRVopP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-define X and y after all feature engineering and encoding\n",
        "X = df.drop(columns = ['Churn'])\n",
        "y = df['Churn'].values\n",
        "\n",
        "# Re-perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 40, stratify=y)\n",
        "\n",
        "# Re-identify numerical columns (they might have changed with new features)\n",
        "num_cols_updated = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Re-apply StandardScaler to the numerical columns of the new X_train and X_test\n",
        "scaler= StandardScaler()\n",
        "X_train[num_cols_updated] = scaler.fit_transform(X_train[num_cols_updated])\n",
        "X_test[num_cols_updated] = scaler.transform(X_test[num_cols_updated])\n",
        "\n",
        "\n",
        "lasso = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "lasso_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Lasso_Coefficient': np.abs(lasso.coef_)\n",
        "}).sort_values('Lasso_Coefficient', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(f\"Lasso best alpha: {lasso.alpha_:.6f}\")\n",
        "print(\"=\" * 55)\n",
        "print(\"Lasso — Non-zero features (selected):\")\n",
        "lasso_selected = lasso_importance[lasso_importance['Lasso_Coefficient'] > 0]\n",
        "print(lasso_selected.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Plot Lasso\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(\n",
        "    data=lasso_selected.head(15),\n",
        "    x='Lasso_Coefficient',\n",
        "    y='Feature',\n",
        "    palette='Oranges_r'\n",
        ")\n",
        "plt.title('Feature Importance — Lasso (L1) Regression', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('|Coefficient|')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AmEgansuVxhH"
      },
      "id": "AmEgansuVxhH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Feature Importance"
      ],
      "metadata": {
        "id": "uHrDUG4MWFFH"
      },
      "id": "uHrDUG4MWFFH"
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'RF_Importance': rf.feature_importances_\n",
        "}).sort_values('RF_Importance', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"Random Forest — Top 15 Feature Importances:\")\n",
        "print(\"=\" * 55)\n",
        "print(rf_importance.head(15).to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Plot RF\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(\n",
        "    data=rf_importance.head(15),\n",
        "    x='RF_Importance',\n",
        "    y='Feature',\n",
        "    palette='Purples_r'\n",
        ")\n",
        "plt.title('Feature Importance — Random Forest', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7RxYJnHJWFnb"
      },
      "id": "7RxYJnHJWFnb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Feature Subset — Combining all methods"
      ],
      "metadata": {
        "id": "tzhqViMCWKtz"
      },
      "id": "tzhqViMCWKtz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank features across all 3 methods\n",
        "all_features = X.columns.tolist()\n",
        "\n",
        "# Rank by each method (lower rank = more important)\n",
        "filter_rank = {f: i for i, f in enumerate(top15_filter)}\n",
        "lasso_rank  = {f: i for i, f in\n",
        "               enumerate(lasso_importance['Feature'].tolist())}\n",
        "rf_rank     = {f: i for i, f in\n",
        "               enumerate(rf_importance['Feature'].tolist())}\n",
        "\n",
        "ranking_df = pd.DataFrame({'Feature': all_features})\n",
        "ranking_df['Filter_Rank'] = ranking_df['Feature'].map(\n",
        "    lambda f: filter_rank.get(f, len(all_features))\n",
        ")\n",
        "ranking_df['Lasso_Rank']  = ranking_df['Feature'].map(\n",
        "    lambda f: lasso_rank.get(f, len(all_features))\n",
        ")\n",
        "ranking_df['RF_Rank']     = ranking_df['Feature'].map(\n",
        "    lambda f: rf_rank.get(f, len(all_features))\n",
        ")\n",
        "ranking_df['Avg_Rank']    = ranking_df[\n",
        "    ['Filter_Rank', 'Lasso_Rank', 'RF_Rank']\n",
        "].mean(axis=1)\n",
        "\n",
        "ranking_df = ranking_df.sort_values('Avg_Rank').reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Final Feature Ranking (All Methods Combined):\")\n",
        "print(\"=\" * 60)\n",
        "print(ranking_df.head(15).to_string(index=False))\n",
        "\n",
        "# ── Select Top 12 Final Features ─────────────────────────────\n",
        "final_features = ranking_df.head(12)['Feature'].tolist()\n",
        "print(\"\\n✅ Final Selected Features:\")\n",
        "for i, f in enumerate(final_features, 1):\n",
        "    print(f\"  {i:2}. {f}\")\n",
        "\n",
        "# ── Final dataframe ready for modeling ───────────────────────\n",
        "df_model = df[final_features + ['Churn']].copy()\n",
        "print(f\"\\ndf_model shape: {df_model.shape}\")\n",
        "print(df_model.head())\n"
      ],
      "metadata": {
        "id": "BmevYEvyWL7X"
      },
      "id": "BmevYEvyWL7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# E. Textual Justification for Final Feature Subset\n",
        "# ============================================================\n",
        "\n",
        "justification = \"\"\"\n",
        "╔══════════════════════════════════════════════════════════════╗\n",
        "║         PHASE 3 — FINAL FEATURE SUBSET JUSTIFICATION        ║\n",
        "╚══════════════════════════════════════════════════════════════╝\n",
        "\n",
        "1. FEATURE ENGINEERING\n",
        "   ─────────────────────────────────────────────────────────\n",
        "   • Tenure_Group: Binning tenure into 4 loyalty segments\n",
        "     (New/Developing/Established/Loyal) captures non-linear\n",
        "     churn behavior — new customers churn at much higher rates.\n",
        "\n",
        "   • Avg_Monthly_Spend: TotalCharges / (tenure+1) captures\n",
        "     whether a customer's spending is rising or falling over\n",
        "     time, which is more informative than raw TotalCharges alone.\n",
        "\n",
        "   • Service_Count: The total number of add-on services acts\n",
        "     as a proxy for switching cost — customers with more\n",
        "     services face higher friction when leaving.\n",
        "\n",
        "2. FILTER-BASED SELECTION (Chi2 + ANOVA)\n",
        "   ─────────────────────────────────────────────────────────\n",
        "   • Chi-Squared identified categorical features most\n",
        "     statistically dependent on Churn (p < 0.05).\n",
        "   • ANOVA F-Test confirmed continuous features (tenure,\n",
        "     MonthlyCharges, TotalCharges) with highest group\n",
        "     mean differences between churned/non-churned customers.\n",
        "   • Features failing both tests (p > 0.05 in both) were\n",
        "     considered statistically insignificant and down-ranked.\n",
        "\n",
        "3. MODEL-BASED SELECTION\n",
        "   ─────────────────────────────────────────────────────────\n",
        "   • Lasso (L1): By penalizing coefficients toward zero,\n",
        "     Lasso automatically eliminated multicollinear and\n",
        "     redundant features. Only features surviving L1\n",
        "     shrinkage carry independent predictive signal.\n",
        "   • Random Forest: Impurity-based importance scores\n",
        "     capture non-linear relationships and interactions\n",
        "     that linear methods like Lasso may miss.\n",
        "\n",
        "4. FINAL SELECTION RATIONALE\n",
        "   ─────────────────────────────────────────────────────────\n",
        "   The final 12 features were chosen by averaging ranks\n",
        "   across all three methods. This ensemble approach is more\n",
        "   robust than relying on any single method:\n",
        "   - It avoids overfitting to one selection criterion.\n",
        "   - Features consistently ranked high across methods\n",
        "     are genuinely predictive, not method-specific artifacts.\n",
        "   - Multicollinear OHE dummy pairs (e.g.,\n",
        "     'InternetService_No' vs 'InternetService_Fiber optic')\n",
        "     were deduplicated keeping only the higher-ranked one.\n",
        "\"\"\"\n",
        "print(justification)\n"
      ],
      "metadata": {
        "id": "40j2eGJIWQ-j"
      },
      "id": "40j2eGJIWQ-j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 60.005711,
      "end_time": "2021-06-29T09:03:36.232671",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-29T09:02:36.226960",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}